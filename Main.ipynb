{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "97thj9hmfKFF"
      },
      "outputs": [],
      "source": [
        "#Import all the libraries needed\n",
        "import pandas as pd    # to load dataset\n",
        "import numpy as np     # for mathematic equation\n",
        "from nltk.corpus import stopwords   # to get collection of stopwords\n",
        "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
        "from tensorflow.keras.models import Sequential     # the model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
        "from tensorflow.keras.models import load_model   # load saved model\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv(\"/content/phm_train.csv\")"
      ],
      "metadata": {
        "id": "ygTrHIXElgzM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = pd.read_csv(\"/content/phm_test.csv\")"
      ],
      "metadata": {
        "id": "Dnv6pIRKz4bf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byO7tm9hl9vz",
        "outputId": "9000bce3-400e-4789-a400-fb65a3b60cc0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          tweet_id  label                                              tweet\n",
            "0     6.430000e+17      0  user_mention all i can tell you is i have had ...\n",
            "1     6.440000e+17      0  my doctor told me stop he gave me sum pop i mi...\n",
            "2     8.150000e+17      1  i take tylenol and i wake up in the middle of ...\n",
            "3     6.820000e+17      0  i got xans in an advil bottle i dont take them...\n",
            "4     6.440000e+17      1  mom says i need to stop eating so much bc ive ...\n",
            "...            ...    ...                                                ...\n",
            "9986  6.480000e+17      1                          that vicodin messed me up\n",
            "9987  5.710000e+17      0                  user_mention get some tylenol lol\n",
            "9988  6.470000e+17      0                          like a walking tamiflu ad\n",
            "9989  6.990000e+17      0                         klay and steph on steroids\n",
            "9990  8.230000e+17      0                    horrible pops another xanax url\n",
            "\n",
            "[9991 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URXTG2lw0NL9",
        "outputId": "7aa7f34d-08c6-4d91-b821-871ad715f246"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          tweet_id  label                                              tweet\n",
            "0     6.411550e+17      0  when you try to run away from the iv needle so...\n",
            "1     6.425520e+17      1  i just knew i took an ambien for sleep too ear...\n",
            "2     6.410410e+17      1  i mean i get that my celexa is the reason behi...\n",
            "3     7.476620e+17      0  if you call me dumb or her dumb one more time ...\n",
            "4     6.406830e+17      0  i do not want to go to the grocery store but i...\n",
            "...            ...    ...                                                ...\n",
            "3326  6.392340e+17      0                         fina take this xanax knock\n",
            "3327  6.398700e+17      0                user_mention yr on citalopram right\n",
            "3328  6.433340e+17      0                   user_mention yeah im going norco\n",
            "3329  5.588580e+17      0                   user_mention tylenol w codin lol\n",
            "3330  7.131560e+17      0                thats determination on steroids url\n",
            "\n",
            "[3331 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "english_stops = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y082qTfvl_Y3",
        "outputId": "977695b1-5885-41d8-d2a9-4e79532aa7bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_train_dataset():\n",
        "    x_train = data_train['tweet']\n",
        "    y_train = data_train['label']\n",
        "\n",
        "    x_train = x_train.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
        "    x_train = x_train.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
        "    x_train = x_train.apply(lambda tweet: [w for w in tweet.split() if w not in english_stops])  # remove stop words\n",
        "    x_train = x_train.apply(lambda tweet: [w.lower() for w in tweet])   # lower case\n",
        "\n",
        "    return x_train, y_train\n",
        "\n",
        "x_train, y_train = load_train_dataset()\n",
        "\n",
        "print('tweet')\n",
        "print(x_train, '\\n')\n",
        "print('label')\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruKr_BgSu0ig",
        "outputId": "8fe843d6-8d17-4afb-87c9-39d9451c5ce1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet\n",
            "0       [user, mention, tell, relapses, cure, hear, do...\n",
            "1       [doctor, told, stop, gave, sum, pop, mix, w, a...\n",
            "2       [take, tylenol, wake, middle, night, put, ice,...\n",
            "3       [got, xans, advil, bottle, dont, take, shits, ...\n",
            "4       [mom, says, need, stop, eating, much, bc, ive,...\n",
            "                              ...                        \n",
            "9986                                    [vicodin, messed]\n",
            "9987                   [user, mention, get, tylenol, lol]\n",
            "9988                         [like, walking, tamiflu, ad]\n",
            "9989                              [klay, steph, steroids]\n",
            "9990                [horrible, pops, another, xanax, url]\n",
            "Name: tweet, Length: 9991, dtype: object \n",
            "\n",
            "label\n",
            "0       0\n",
            "1       0\n",
            "2       1\n",
            "3       0\n",
            "4       1\n",
            "       ..\n",
            "9986    1\n",
            "9987    0\n",
            "9988    0\n",
            "9989    0\n",
            "9990    0\n",
            "Name: label, Length: 9991, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_dataset():\n",
        "    x_test = data_test['tweet']\n",
        "    y_test = data_test['label']\n",
        "\n",
        "    x_test = x_test.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
        "    x_test = x_test.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
        "    x_test = x_test.apply(lambda tweet: [w for w in tweet.split() if w not in english_stops])  # remove stop words\n",
        "    x_test = x_test.apply(lambda tweet: [w.lower() for w in tweet])   # lower case\n",
        "\n",
        "    return x_test, y_test\n",
        "\n",
        "x_test, y_test = load_test_dataset()\n",
        "\n",
        "print('tweet')\n",
        "print(x_test, '\\n')\n",
        "print('label')\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VYnZgOuwNBe",
        "outputId": "8e88e3b0-c276-46c4-cd2d-f421daf2cb76"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet\n",
            "0       [try, run, away, iv, needle, doctor, drug, w, ...\n",
            "1       [knew, took, ambien, sleep, early, im, ready, ...\n",
            "2       [mean, get, celexa, reason, behind, lot, weigh...\n",
            "3       [call, dumb, dumb, one, time, dont, care, many...\n",
            "4       [want, go, grocery, store, cant, pay, anyone, ...\n",
            "                              ...                        \n",
            "3326                           [fina, take, xanax, knock]\n",
            "3327               [user, mention, yr, citalopram, right]\n",
            "3328              [user, mention, yeah, im, going, norco]\n",
            "3329              [user, mention, tylenol, w, codin, lol]\n",
            "3330                [thats, determination, steroids, url]\n",
            "Name: tweet, Length: 3331, dtype: object \n",
            "\n",
            "label\n",
            "0       0\n",
            "1       1\n",
            "2       1\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "3326    0\n",
            "3327    0\n",
            "3328    0\n",
            "3329    0\n",
            "3330    0\n",
            "Name: label, Length: 3331, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train Set')\n",
        "print(x_train, '\\n')\n",
        "print(x_test, '\\n')\n",
        "print('Test Set')\n",
        "print(y_train, '\\n')\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb2mDv4P2Lvy",
        "outputId": "df6a86a7-08bf-4b66-9a23-9194031c8609"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set\n",
            "0       [user, mention, tell, relapses, cure, hear, do...\n",
            "1       [doctor, told, stop, gave, sum, pop, mix, w, a...\n",
            "2       [take, tylenol, wake, middle, night, put, ice,...\n",
            "3       [got, xans, advil, bottle, dont, take, shits, ...\n",
            "4       [mom, says, need, stop, eating, much, bc, ive,...\n",
            "                              ...                        \n",
            "9986                                    [vicodin, messed]\n",
            "9987                   [user, mention, get, tylenol, lol]\n",
            "9988                         [like, walking, tamiflu, ad]\n",
            "9989                              [klay, steph, steroids]\n",
            "9990                [horrible, pops, another, xanax, url]\n",
            "Name: tweet, Length: 9991, dtype: object \n",
            "\n",
            "0       [try, run, away, iv, needle, doctor, drug, w, ...\n",
            "1       [knew, took, ambien, sleep, early, im, ready, ...\n",
            "2       [mean, get, celexa, reason, behind, lot, weigh...\n",
            "3       [call, dumb, dumb, one, time, dont, care, many...\n",
            "4       [want, go, grocery, store, cant, pay, anyone, ...\n",
            "                              ...                        \n",
            "3326                           [fina, take, xanax, knock]\n",
            "3327               [user, mention, yr, citalopram, right]\n",
            "3328              [user, mention, yeah, im, going, norco]\n",
            "3329              [user, mention, tylenol, w, codin, lol]\n",
            "3330                [thats, determination, steroids, url]\n",
            "Name: tweet, Length: 3331, dtype: object \n",
            "\n",
            "Test Set\n",
            "0       0\n",
            "1       0\n",
            "2       1\n",
            "3       0\n",
            "4       1\n",
            "       ..\n",
            "9986    1\n",
            "9987    0\n",
            "9988    0\n",
            "9989    0\n",
            "9990    0\n",
            "Name: label, Length: 9991, dtype: int64 \n",
            "\n",
            "0       0\n",
            "1       1\n",
            "2       1\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "3326    0\n",
            "3327    0\n",
            "3328    0\n",
            "3329    0\n",
            "3330    0\n",
            "Name: label, Length: 3331, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENCODE REVIEW\n",
        "token = Tokenizer(lower=False)    # no need lower, because already lowered the data\n",
        "token.fit_on_texts(x_train)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)"
      ],
      "metadata": {
        "id": "fx2hzt3aByJr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculates the average tweet length (in number of words) and rounds it up to use as the maximum sequence length for padding.\n",
        "def get_max_length():\n",
        "    tweet_length = []\n",
        "    for tweet in x_train:\n",
        "        tweet_length.append(len(tweet))\n",
        "\n",
        "    return int(np.ceil(np.mean(tweet_length)))"
      ],
      "metadata": {
        "id": "t8yKV4hs2Yr3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_max_length())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhW3oiGQ3hyw",
        "outputId": "304fd47f-a6d0-48e9-f2a1-3fe06d405188"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = get_max_length()\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum tweet length: ', max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsM8aNIl3wGk",
        "outputId": "7802832f-8894-4b49-9193-1ed6d8061d04"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded X Train\n",
            " [[    2     1   200 ...   944  3624  1952]\n",
            " [  115   122   147 ...   193    40   322]\n",
            " [    6     3   330 ...   626  1710    29]\n",
            " ...\n",
            " [    7   529  1739 ...     0     0     0]\n",
            " [12658 12659     8 ...     0     0     0]\n",
            " [  645  1436   174 ...     0     0     0]] \n",
            "\n",
            "Encoded X Test\n",
            " [[  98  606  109 ...  193    4  318]\n",
            " [ 585   11   56 ...   16  707   55]\n",
            " [ 327   12 1209 ...  778    5   88]\n",
            " ...\n",
            " [   2    1  126 ...    0    0    0]\n",
            " [   2    1    3 ...    0    0    0]\n",
            " [  59    8    9 ...    0    0    0]] \n",
            "\n",
            "Maximum tweet length:  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.build(input_shape=(None, max_length))\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "2N6lRX0FJ0CP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSZbbqeNLmmk",
        "outputId": "0d8102b7-e9cc-4d5c-e2a4-d5c5ef0f7f20"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "6_vHOTCUf9qR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # LSTM Model\n",
        "# EMBED_DIM = 32\n",
        "# LSTM_OUT = 64\n",
        "\n",
        "# LSTM_model = Sequential()\n",
        "# LSTM_model.add(Embedding(12660, 32, input_length = 10))\n",
        "# LSTM_model.add(LSTM(64))\n",
        "# LSTM_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# print(LSTM_model.summary())"
      ],
      "metadata": {
        "id": "cCvIOFJE5jqF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Model\n",
        "EMBED_DIM = 100\n",
        "LSTM_OUT = 128\n",
        "\n",
        "LSTM_model = Sequential()\n",
        "LSTM_model.add(Embedding(total_words, EMBED_DIM))  # No need for input_length\n",
        "LSTM_model.add(LSTM(LSTM_OUT, return_sequences=True, dropout=0.3, recurrent_dropout=0.1))\n",
        "LSTM_model.add(LSTM(80, dropout=0.3))\n",
        "# LSTM_model.add(Dense(1, activation='sigmoid'))\n",
        "LSTM_model.add(Dense(1, activation='relu'))\n",
        "\n",
        "LSTM_model.build(input_shape=(None, 10))\n",
        "LSTM_model.summary()"
      ],
      "metadata": {
        "id": "oN6CbQu-EEd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "f56e1b1f-d3c3-41f0-d51b-998774b7a638"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m1,266,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m117,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │        \u001b[38;5;34m66,880\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m81\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,266,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,880</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,450,209\u001b[0m (5.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,450,209</span> (5.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,450,209\u001b[0m (5.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,450,209</span> (5.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "6fzagOvOMYg1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'models/LSTM.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "yjKQ1v7jeKIq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Model Training\n",
        "LSTM_model.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP0FNVraeQWJ",
        "outputId": "dfea822a-1a52-49aa-e820-e9e80d79423d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7158 - loss: 0.8152\n",
            "Epoch 1: accuracy improved from -inf to 0.73806, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 91ms/step - accuracy: 0.7163 - loss: 0.8103\n",
            "Epoch 2/5\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7808 - loss: 0.4555\n",
            "Epoch 2: accuracy improved from 0.73806 to 0.80312, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - accuracy: 0.7814 - loss: 0.4553\n",
            "Epoch 3/5\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8674 - loss: 0.3810\n",
            "Epoch 3: accuracy improved from 0.80312 to 0.86408, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 108ms/step - accuracy: 0.8673 - loss: 0.3811\n",
            "Epoch 4/5\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8862 - loss: 0.3328\n",
            "Epoch 4: accuracy improved from 0.86408 to 0.88570, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - accuracy: 0.8861 - loss: 0.3330\n",
            "Epoch 5/5\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8673 - loss: 0.3808\n",
            "Epoch 5: accuracy did not improve from 0.88570\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.8674 - loss: 0.3800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79f9ee28a8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Model Testing\n",
        "pred = LSTM_model.predict(x=x_test)\n",
        "y_pred = (pred >= 0.5) * 1\n",
        "\n",
        "true = 0\n",
        "for i, y in enumerate(y_test):\n",
        "    if y == y_pred[i]:\n",
        "        true += 1\n",
        "\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
        "print('Accuracy: {}'.format(true/len(y_pred)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLR4WaOoefI0",
        "outputId": "00b305cd-4a18-44f0-8573-94b8021fb8d3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n",
            "Correct Prediction: 2726\n",
            "Wrong Prediction: 605\n",
            "Accuracy: 81.83728610027019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bi-LSTM**"
      ],
      "metadata": {
        "id": "8j5GF2KqgDwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bi-LSTM Model\n",
        "EMBED_DIM = 100\n",
        "BILSTM_OUT = 128\n",
        "\n",
        "BILSTM_model = Sequential()\n",
        "BILSTM_model.add(Embedding(total_words, EMBED_DIM))  # No need for input_length\n",
        "BILSTM_model.add(Bidirectional(LSTM(BILSTM_OUT, return_sequences=True, dropout=0.3, recurrent_dropout=0.1)))\n",
        "BILSTM_model.add(LSTM(80, dropout=0.3))\n",
        "# BILSTM_model.add(Dense(1, activation='sigmoid'))\n",
        "BILSTM_model.add(Dense(1, activation='relu'))\n",
        "\n",
        "\n",
        "BILSTM_model.build(input_shape=(None, 10))\n",
        "BILSTM_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "UJyDEcdWfDGD",
        "outputId": "fbb8954f-a468-44c7-8181-5788f9d7c18f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m1,266,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m234,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │       \u001b[38;5;34m107,840\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m81\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,266,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">107,840</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,608,417\u001b[0m (6.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,608,417</span> (6.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,608,417\u001b[0m (6.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,608,417</span> (6.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BILSTM_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "HWgh4mQahAPt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_bilstm = ModelCheckpoint(\n",
        "    'models/BiLSTM.h5',   # <-- different file name\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "9KH9h3Dpf2N8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bi-LSTM Model Training\n",
        "BILSTM_model.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBOzng4Sgdsq",
        "outputId": "b1c1ac29-2922-4c8d-c5a0-021e8f86da0b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.7224 - loss: 0.8730\n",
            "Epoch 1: accuracy did not improve from 0.91032\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 170ms/step - accuracy: 0.7228 - loss: 0.8700\n",
            "Epoch 2/5\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.8504 - loss: 0.4146\n",
            "Epoch 2: accuracy did not improve from 0.91032\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 172ms/step - accuracy: 0.8503 - loss: 0.4149\n",
            "Epoch 3/5\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.7729 - loss: 0.5770\n",
            "Epoch 3: accuracy did not improve from 0.91032\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 173ms/step - accuracy: 0.7731 - loss: 0.5770\n",
            "Epoch 4/5\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8696 - loss: 0.3570\n",
            "Epoch 4: accuracy did not improve from 0.91032\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 169ms/step - accuracy: 0.8696 - loss: 0.3572\n",
            "Epoch 5/5\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.8917 - loss: 0.3147\n",
            "Epoch 5: accuracy did not improve from 0.91032\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 171ms/step - accuracy: 0.8918 - loss: 0.3149\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79f9f57f3690>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bi-LSTM Model Testing\n",
        "pred1 = BILSTM_model.predict(x=x_test)\n",
        "y_pred1 = (pred1 >= 0.5) * 1\n",
        "\n",
        "true = 0\n",
        "for i, y in enumerate(y_test):\n",
        "    if y == y_pred1[i]:\n",
        "        true += 1\n",
        "\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred1) - true))\n",
        "print('Accuracy: {}'.format(true/len(y_pred1)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoHXnZohg4wf",
        "outputId": "98a815e8-afd2-42b3-fe26-8d6782ef0aaf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step\n",
            "Correct Prediction: 2734\n",
            "Wrong Prediction: 597\n",
            "Accuracy: 82.07745421795258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9gtgaKxFhhVD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
